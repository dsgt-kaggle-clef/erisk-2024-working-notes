
@book{crestani_early_2022,
	title = {Early {Detection} of {Mental} {Health} {Disorders} by {Social} {Media} {Monitoring}: {The} {First} {Five} {Years} of the {eRisk} {Project}},
	isbn = {978-3-031-04430-4},
	shorttitle = {Early {Detection} of {Mental} {Health} {Disorders} by {Social} {Media} {Monitoring}},
	abstract = {eRisk stands for Early Risk Prediction on the Internet. It is concerned with the exploration of techniques for the early detection of mental health disorders which manifest in the way people write and communicate on the internet, in particular in user generated content (e.g. Facebook, Twitter, or other social media).Early detection technologies can be employed in several different areas but particularly in those related to health and safety. For instance, early alerts could be sent when the writing of a teenager starts showing increasing signs of depression, or when a social media user starts showing suicidal inclinations, or again when a potential offender starts publishing antisocial threats on a blog, forum or social network. eRisk has been the pioneer of a new interdisciplinary area of research that is potentially applicable to a wide variety of situations, problems and personal profiles.This book presents the best results of the first five years of the eRisk project which started in 2017 and developed into one of the most successful track of CLEF, the Conference and Lab of the Evaluation Forum.},
	language = {en},
	publisher = {Springer International Publishing},
	author = {Crestani, Fabio and Losada, David E. and Parapar, Javier},
	month = sep,
	year = {2022},
	note = {Google-Books-ID: Jp35zgEACAAJ},
	keywords = {Computers / Artificial Intelligence / General, Computers / Data Science / General, Computers / Database Administration \& Management, Social Science / Media Studies, Technology \& Engineering / Engineering (General), Technology \& Engineering / General},
}

@inproceedings{parapar_overview_2023,
	address = {Cham},
	title = {Overview of {eRisk} 2023: {Early} {Risk} {Prediction} on the {Internet}},
	isbn = {978-3-031-42448-9},
	abstract = {This paper provides an overview of eRisk 2023, the seventh edition of the CLEF conference's lab dedicated to early risk detection. Since its inception, our lab has aimed to explore evaluation methodologies, effectiveness metrics, and other processes associated with early risk detection. The applications of early alerting models are diverse and encompass various domains, including health and safety. eRisk 2023 consisted of three tasks. The first task involved ranking sentences based on their relevance to standardised depression symptoms. The second task focused on early detection of signs related to pathological gambling. The third task required participants to automatically estimate an eating disorders questionnaire by analysing user writings on social media.},
	booktitle = {Experimental {IR} {Meets} {Multilinguality}, {Multimodality}, and {Interaction}},
	publisher = {Springer Nature Switzerland},
	author = {Parapar, Javier and Martín-Rodilla, Patricia and Losada, David E. and Crestani, Fabio},
	editor = {Arampatzis, Avi and Kanoulas, Evangelos and Tsikrika, Theodora and Vrochidis, Stefanos and Giachanou, Anastasia and Li, Dan and Aliannejadi, Mohammad and Vlachos, Michalis and Faggioli, Guglielmo and Ferro, Nicola},
	year = {2023},
	pages = {294--315},
}

@misc{reimers_sentence-bert_2019,
	title = {Sentence-{BERT}: {Sentence} {Embeddings} using {Siamese} {BERT}-{Networks}},
	author = {Reimers, Nils and Gurevych, Iryna},
	year = {2019},
	note = {\_eprint: 1908.10084},
}

@article{recharla_notebook_nodate,
	title = {Notebook for the {eRisk} {Lab} at {CLEF} 2023},
	abstract = {Regardless of age, gender, or color, depression affects people all over the world. People feel increasingly at ease sharing their opinions on social networking sites practically every day in the present era of communication and technology. Reddit is a social networking site consisting of subreddits, or singletopic communities, created, maintained, and frequented by anonymous users. Users have the ability to post, comment on, and reply to posts within subreddits. Data for this suggested model is gathered from user posts on Reddit. Our approach involves ranking sentences from a collection of Reddit posts according to their relevance to a depression symptom for the 21 symptoms of depression from the BDI-II Questionnaire.},
	language = {en},
	author = {Recharla, Naveen and Bolimera, Prasanthi and Gupta, Yash and Madasamy, Anand Kumar},
	file = {Recharla et al. - Notebook for the eRisk Lab at CLEF 2023.pdf:C\:\\Users\\david\\Zotero\\storage\\ZNRBJ4FY\\Recharla et al. - Notebook for the eRisk Lab at CLEF 2023.pdf:application/pdf},
        year = {2023},
}

@article{wang_notebook_nodate,
	title = {Notebook for the {eRisk} {Lab} at {CLEF} 2023},
	abstract = {This paper introduces the University of Ottawa’s participation in Task 1 of the eRisk 2023 shared task at CLEF 2023. As early intervention of depression becomes more and more important, we are striving to build a system to search for depression symptoms. By participating, we could evaluate the effectiveness of our search techniques and identify areas for improvement. Our methods focused on extracting relevant sentences for each symptom in the Beck’s Depression Inventory questionnaire and providing a ranking for further investigation. To rank the sentences, we represented them as neural embedding vectors, then we computed their cosine similarity to query embedding vectors. We constructed one query for each of the 21 symptoms of interest, based on the corresponding question and possible answers in the questionnaire.},
	language = {en},
	author = {Wang, Yuxi and Inkpen, Diana},
	file = {Wang and Inkpen - Notebook for the eRisk Lab at CLEF 2023.pdf:C\:\\Users\\david\\Zotero\\storage\\Y4JNZWYD\\Wang and Inkpen - Notebook for the eRisk Lab at CLEF 2023.pdf:application/pdf},
        year = {2023},
}

@article{beck_beck_1996,
	title = {Beck depression inventory},
	author = {Beck, Aaron T and Steer, Robert A and Brown, Gregory K and {others}},
	year = {1996},
	note = {Publisher: Psychological Corporation San Antonio, TX},
}

@article{grigore_notebook_nodate,
	title = {Notebook for the {eRisk} {Lab} at {CLEF} 2023},
	abstract = {In this paper, we describe a topic-driven approach for detecting the severity of eating disorder symptoms. We extract more task relevant embeddings with the help of a MentalBERT model pretrained on ED data. We then employ the use of BERTopic to extract probability scores associated with identified discussion themes. These become features used to predict the answers given by users in the Eating Disorder Examination Questionnaire, based on their social media post history. The task is introduced in the CLEF eRisk 2023 competition, in which we participate as team RiskBusters. We obtain the best results in the Shape Concern Subscale and are competitive on all the other metrics.},
	language = {en},
	author = {Grigore, Diana-Nicoleta and Pintilie, Ioana},
	file = {Grigore and Pintilie - Notebook for the eRisk Lab at CLEF 2023.pdf:C\:\\Users\\david\\Zotero\\storage\\HIVXEG6C\\Grigore and Pintilie - Notebook for the eRisk Lab at CLEF 2023.pdf:application/pdf},
        year = {2023},
}

@misc{noauthor_getting_nodate,
	title = {Getting {Started} — {Luigi} 3.5.1 documentation},
	url = {https://luigi.readthedocs.io/en/stable/#},
	urldate = {2024-05-31},
        year = {2024},
}

@article{robertson_probabilistic_2009,
	title = {The {Probabilistic} {Relevance} {Framework}: {BM25} and {Beyond}},
	volume = {3},
	issn = {1554-0669, 1554-0677},
	shorttitle = {The {Probabilistic} {Relevance} {Framework}},
	url = {http://www.nowpublishers.com/article/Details/INR-019},
	doi = {10.1561/1500000019},
	abstract = {The Probabilistic Relevance Framework (PRF) is a formal framework for document retrieval, grounded in work done in the 1970–1980s, which led to the development of one of the most successful text-retrieval algorithms, BM25. In recent years, research in the PRF has yielded new retrieval models capable of taking into account document meta-data (especially structure and link-graph information). Again, this has led to one of the most successful Web-search and corporate-search algorithms, BM25F. This work presents the PRF from a conceptual point of view, describing the probabilistic modelling assumptions behind the framework and the diﬀerent ranking algorithms that result from its application: the binary independence model, relevance feedback models, BM25 and BM25F. It also discusses the relation between the PRF and other statistical models for IR, and covers some related topics, such as the use of non-textual features, and parameter optimisation for models with free parameters.},
	language = {en},
	number = {4},
	urldate = {2024-05-31},
	journal = {Foundations and Trends® in Information Retrieval},
	author = {Robertson, Stephen and Zaragoza, Hugo},
	year = {2009},
	pages = {333--389},
	file = {Robertson and Zaragoza - 2009 - The Probabilistic Relevance Framework BM25 and Be.pdf:C\:\\Users\\david\\Zotero\\storage\\EKIMSHPJ\\Robertson and Zaragoza - 2009 - The Probabilistic Relevance Framework BM25 and Be.pdf:application/pdf},
}

@misc{noauthor_sentence-transformersall-minilm-l6-v2_nodate,
	title = {sentence-transformers/all-{MiniLM}-{L6}-v2 · {Hugging} {Face}},
	url = {https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2},
	urldate = {2024-05-31},
        year = {2024},
}

@misc{noauthor_google-bertbert-base-uncased_nodate,
	title = {google-bert/bert-base-uncased · {Hugging} {Face}},
	url = {https://huggingface.co/google-bert/bert-base-uncased},
	urldate = {2024-05-31},
        year = {2024},
}

@misc{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	urldate = {2024-05-31},
	publisher = {arXiv},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = may,
	year = {2019},
	note = {arXiv:1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\david\\Zotero\\storage\\JQJQ3RKK\\Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\david\\Zotero\\storage\\WJFMXLRY\\1810.html:text/html},
}

@techreport{fodor_survey_2002,
	title = {A {Survey} of {Dimension} {Reduction} {Techniques}},
	url = {http://www.osti.gov/servlets/purl/15002155-mumfPN/native/},
	language = {en},
	number = {UCRL-ID-148494, 15002155},
	urldate = {2024-05-31},
	author = {Fodor, I K},
	month = may,
	year = {2002},
	doi = {10.2172/15002155},
	pages = {UCRL--ID--148494, 15002155},
	file = {Fodor - 2002 - A Survey of Dimension Reduction Techniques.pdf:C\:\\Users\\david\\Zotero\\storage\\66FEYZA6\\Fodor - 2002 - A Survey of Dimension Reduction Techniques.pdf:application/pdf},
}
